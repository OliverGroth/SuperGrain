{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  #general warning suppression\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "from skimage.io import imread\n",
    "from skimage.draw import polygon\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  #tensorflow deprecration warning suppression\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required to import downloaded Mask_RCNN by below cells. Not needed if installed the repository by pip etc\n",
    "sys.path.append(\"TestNN/crop_seed_instance_segmentation/Mask_RCNN/mrcnn\") \n",
    "\n",
    "from mrcnn.visualize import display_images\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils, visualize\n",
    "\n",
    "sys.path.insert(0, '/Users/buyn/Desktop/project_w_oliver/supergrain')\n",
    "# Import model.py as modellib\n",
    "import model as modellib\n",
    "from model import log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceConfig(Config):\n",
    "    NAME = \"seed\"\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NUM_CLASSES = 1 + 1  # background + 1 seeds\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 8192\n",
    "    DETECTION_MAX_INSTANCES = 1000\n",
    "    IMAGE_RESIZE_MODE = \"pad64\"\n",
    "    RPN_NMS_THRESHOLD = 0.4\n",
    "    DETECTION_MIN_CONFIDENCE = 0\n",
    "\n",
    "config = InferenceConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropSeedsDataset(utils.Dataset):\n",
    "\n",
    "    def load_seeds(self, dataset_dir, input_folder=\"image\", mask_folder=\"mask\"):\n",
    "\n",
    "        self.add_class(\"seed\", 1, \"seed\")\n",
    "        self.dataset_dir = dataset_dir\n",
    "        self.mask_folder = mask_folder\n",
    "        files = sorted([x for x in os.listdir(os.path.join(\n",
    "            dataset_dir, input_folder)) if x.endswith(\".png\")])\n",
    "\n",
    "        for file in files:\n",
    "            self.add_image(\n",
    "                \"seed\",\n",
    "                image_id=file,\n",
    "                path=os.path.join(dataset_dir, input_folder, file)\n",
    "            )\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "\n",
    "        cm = plt.get_cmap(\"jet\")\n",
    "        colors = []\n",
    "        for i in range(256):\n",
    "            colors.append(cm(i)[:3])\n",
    "        colors = (np.array(colors)*255).astype(np.int)\n",
    "        colors = np.unique(colors, axis=1)\n",
    "\n",
    "        info = self.image_info[image_id][\"id\"]\n",
    "        image = imread(os.path.join(\n",
    "            self.dataset_dir, self.mask_folder, info))\n",
    "        mask = []\n",
    "        for color in colors:\n",
    "            m = cv2.inRange(image, color, color)\n",
    "            # if there is a mask, average is not 0\n",
    "            if np.average(m.flatten()) != 0:\n",
    "                mask.append(m)\n",
    "        mask = np.stack(mask, axis=-1)\n",
    "        return mask, np.ones([mask.shape[-1]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=\".\")\n",
    "model.load_weights(\n",
    "    \"data/barley/model_weights/mask_rcnn_barleyseeds_0040.h5\", by_name=True)\n",
    "print(\"model weights loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_dataset = CropSeedsDataset()\n",
    "syn_dataset.load_seeds(\"data/barley/synthetic_test/\")\n",
    "syn_dataset.prepare()\n",
    "\n",
    "print(\"Image Count: {}\".format(len(syn_dataset.image_ids)))\n",
    "print(\"Class Count: {}\".format(syn_dataset.num_classes))\n",
    "for i, info in enumerate(syn_dataset.class_info):\n",
    "    print(\"{:3}. {:50}\".format(i, info['name']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select two random images from the dataset\n",
    "image_ids = np.random.choice(syn_dataset.image_ids, 2)\n",
    "for image_id in image_ids:\n",
    "    image = syn_dataset.load_image(image_id)\n",
    "    mask, class_ids = syn_dataset.load_mask(image_id)\n",
    "    visualize.display_top_masks(image, mask, class_ids, syn_dataset.class_names, limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou = 0.5\n",
    "image_ids = np.random.choice(syn_dataset.image_ids, 2)\n",
    "\n",
    "for image_id in image_ids:\n",
    "    image, image_meta, gt_class_id, gt_bbox, gt_mask = modellib.load_image_gt(syn_dataset, config, image_id)\n",
    "    r = model.detect([image])[0]\n",
    "    visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], [\"\",\"\"],figsize=(5,5))\n",
    "    \n",
    "    recall = utils.compute_recall(r[\"rois\"],gt_bbox,iou)[0]\n",
    "    AP, _,_,_ = utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                                      r['rois'], r['class_ids'], r['scores'], r['masks'],iou_threshold = iou)\n",
    "    \n",
    "    print(\"image:\",image_id)\n",
    "    print(\"bbox iou:\", recall)\n",
    "    print(\"mask AP50:\", AP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_world_dir = \"./data/barley/realworld_test/image\"\n",
    "json_dir = \"./data/barley/realworld_test/metadata.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_dir) as f:\n",
    "    jsondata = json.load(f)\n",
    "files = [x[\"External ID\"] for x in jsondata]\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gt_mask(image,jsondata,n):\n",
    "    shape = (image.shape[0],image.shape[1],len(jsondata[n][\"Label\"][\"seed_mask\"]))\n",
    "    gt_mask = np.full(shape,False,dtype=bool)\n",
    "    for i in range(len(jsondata[n][\"Label\"][\"seed_mask\"])):\n",
    "        _x = []\n",
    "        _y = []\n",
    "        for coord in jsondata[n][\"Label\"][\"seed_mask\"][i][\"geometry\"]:\n",
    "            _x.append(coord[\"x\"])\n",
    "            _y.append(coord[\"y\"])\n",
    "        rr,cc = polygon(_y,_x)\n",
    "        _mask = np.zeros((image.shape[0],image.shape[1]),dtype=np.uint8)\n",
    "        _mask[rr,cc] = True\n",
    "        gt_mask[...,i] = _mask\n",
    "    gt_mask = np.array(gt_mask)\n",
    "    return gt_mask\n",
    "\n",
    "def get_gt_bbox(image,jsondata,n):\n",
    "    gt_bbox = []\n",
    "    for i in range(len(jsondata[n][\"Label\"][\"seed_bbox\"])):\n",
    "\n",
    "        #1. sanitize the coordinate so that it fits the image size range\n",
    "        #2. the order of the coordinate is ambiguous, so calculating to get the top left and bottom right\n",
    "        a = jsondata[n][\"Label\"][\"seed_bbox\"][i][\"geometry\"]\n",
    "\n",
    "        #1. check\n",
    "        for i,coord in enumerate(a):\n",
    "            if coord[\"x\"]<1: a[i][\"x\"]=1\n",
    "            if coord[\"x\"]>=image.shape[1]: a[i][\"x\"]=image.shape[1] -1\n",
    "            if coord[\"y\"]<1: a[i][\"y\"]=1   \n",
    "            if coord[\"y\"]>=image.shape[0]: a[i][\"y\"]=image.shape[0] -1\n",
    "\n",
    "        #2. get top left and bottom right\n",
    "        coords = [np.array([q[\"y\"],q[\"x\"]]) for q in a]\n",
    "        tlidx = np.argmin([np.linalg.norm(coord - np.array([0,0])) for coord in coords])\n",
    "        bridx = np.argmax([np.linalg.norm(coord - np.array([0,0])) for coord in coords])\n",
    "\n",
    "        _c = list(coords[tlidx]) + list(coords[bridx])\n",
    "        gt_bbox.append(_c)\n",
    "    gt_bbox = np.array(gt_bbox)\n",
    "    return gt_bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou = 0.5\n",
    "selected_files = np.random.choice(files,2)\n",
    "print(\"will visualize these files: \", selected_files)\n",
    "\n",
    "for file in selected_files:\n",
    "    image = imread(os.path.join(real_world_dir,file))    \n",
    "    r = model.detect([image],verbose=0)[0]\n",
    "    \n",
    "    #get the position within the jsondata\n",
    "    for i,a in enumerate(jsondata):\n",
    "        if file == a[\"External ID\"]:\n",
    "            n = i\n",
    "    \n",
    "    gt_mask = get_gt_mask(image,jsondata,n)\n",
    "    gt_bbox = get_gt_bbox(image,jsondata,n)\n",
    "    gt_class_id = np.array([1] * len(gt_bbox))\n",
    "    \n",
    "    \n",
    "    recall = utils.compute_recall(r[\"rois\"],gt_bbox,iou)[0]\n",
    "    AP, _,_,_ = utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\n",
    "                                      r['rois'], r['class_ids'], r['scores'], r['masks'],iou_threshold = iou)\n",
    "    \n",
    "    print(\"image:\",file)\n",
    "    print(\"bbox recall:\", recall)\n",
    "    print(\"mask AP50:\", AP)\n",
    "\n",
    "    visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'], [\"\",\"\"],figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=\".\")\n",
    "model.load_weights(\n",
    "    \"data/other/model_weights/rice.h5\", by_name=True)\n",
    "print(\"model weights loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = imread(\"data/other/images/rice.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = model.detect([image], verbose=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize.display_instances(\n",
    "            image, r['rois'], r['masks'], r['class_ids'],\n",
    "            [\"\",\"\"], [\"\" for x in range(len(r['scores']))],\n",
    "            show_bbox=True, show_mask=True,\n",
    "            title=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=\".\")\n",
    "model.load_weights(\n",
    "    \"data/other/model_weights/wheat.h5\", by_name=True)\n",
    "print(\"model weights loaded\")\n",
    "print(\"Hej2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in [os.path.join(\"data/other/images\",x) for x in [\"wheat_AL.jpg\",\"wheat_CS.jpg\",\"wheat_N61.jpg\",\"wheat_Syn01.jpg\"]]:\n",
    "    image = imread(file)\n",
    "    r = model.detect([image], verbose=1)[0]\n",
    "    visualize.display_instances(\n",
    "            image, r['rois'], r['masks'], r['class_ids'],\n",
    "            [\"\",\"\"], [\"\" for x in range(len(r['scores']))],\n",
    "            show_bbox=True, show_mask=True,\n",
    "            title=file,figsize=(5,5))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
