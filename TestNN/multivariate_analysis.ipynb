{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Morphological Descriptors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv_path = \"data/barley/extracted_phenotypes/area_morphology\"\n",
    "\n",
    "li = []\n",
    "for i, file in enumerate([x for x in os.listdir(csv_path) if x.endswith(\".csv\")]):\n",
    "    _df = pd.read_csv(os.path.join(csv_path,file), index_col=0)\n",
    "    name = file.split(\".\")[0]\n",
    "    _df.insert(loc=0,column=\"cultivar\",value = name)\n",
    "    _df.insert(loc=1,column=\"int_category\",value = i)\n",
    "    li.append(_df)\n",
    "\n",
    "#create a dataframe from list\n",
    "df1 = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "# retain only filtered values (i.e. removing non integral area such as awn containing, incomplete detection, partial appearance)\n",
    "df1 = df1[df1[\"filter_level\"] == 3]\n",
    "\n",
    "# for easier interpretation of the dataframe\n",
    "df1 = df1.sort_values('AS_seed_area')\n",
    "df1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the variable that will be used in are from column 7 to 15\n",
    "df1.iloc[:,7:15].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the color ordering in visualization\n",
    "order = ['J647', 'C656', 'C346', 'N009', 'C319', 'K735', 'K692', 'J247', 'U353',\n",
    "       'J064', 'T567', 'I622', 'I304', 'I335', 'U051', 'I626', 'B669', 'E245',\n",
    "       'E612']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = df1.iloc[:,7:15].columns\n",
    "for i, metric in enumerate(metrics):\n",
    "    #draw a boxplot\n",
    "    g = sns.boxplot(y=metric,x=\"cultivar\",data=df1, boxprops=dict(alpha=.3),order=order)\n",
    "    g.set_xticklabels(g.get_xticklabels(),rotation=90,ha=\"center\")\n",
    "    \n",
    "    #draw a swarmplot over the boxplot\n",
    "    g = sns.swarmplot(y=metric,x=\"cultivar\",data=df1,s=1.5,order=order)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reuse the df1 variable above or read again with the below cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"data/barley/extracted_phenotypes/area_morphology\"\n",
    "\n",
    "li = []\n",
    "for i, file in enumerate([x for x in os.listdir(csv_path) if x.endswith(\".csv\")]):\n",
    "    _df = pd.read_csv(os.path.join(csv_path,file), index_col=0)\n",
    "    name = file.split(\".\")[0]\n",
    "    _df.insert(loc=0,column=\"cultivar\",value = name)\n",
    "    _df.insert(loc=1,column=\"int_category\",value = i)\n",
    "    li.append(_df)\n",
    "\n",
    "#create a dataframe from list\n",
    "df1 = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "# retain only filtered values (i.e. removing non integral area such as awn containing, incomplete detection, partial appearance)\n",
    "df1 = df1[df1[\"filter_level\"] == 3]\n",
    "\n",
    "# for easier interpretation of the dataframe\n",
    "df1 = df1.sort_values('AS_seed_area')\n",
    "df1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize before PCA\n",
    "_df1 = df1.iloc[:,7:15].apply(lambda x: (x-x.mean())/x.std(), axis=0)\n",
    "#PCA\n",
    "pca1 = PCA(n_components=None)\n",
    "X = pca1.fit_transform(_df1)\n",
    "embed1 = pd.DataFrame(X, columns=[\"PC{}\".format(x + 1) for x in range(len(_df1.columns))])\n",
    "embed1.index = _df1.index\n",
    "embed1.insert(loc=0,column=\"cultivar\",value = df1[\"cultivar\"])\n",
    "embed1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla PCA Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#plot PCA on PC1 and PC2\n",
    "pc = 1\n",
    "g = sns.scatterplot(x=\"PC\"+str(pc), y=\"PC\"+str(pc+1),\n",
    "                data=embed1, hue=\"cultivar\", alpha=1,linewidth=0.1,s=10,hue_order=order)\n",
    "\n",
    "#add variance explained to axis\n",
    "plt.xlabel(\"PC%s (%s %%)\" %\n",
    "           (str(pc), np.round(pca1.explained_variance_ratio_[pc-1]*100, 2)))\n",
    "plt.ylabel(\"PC%s (%s %%)\" % (\n",
    "    str(pc+1), np.round(pca1.explained_variance_ratio_[pc]*100, 2)))\n",
    "\n",
    "\n",
    "#add legend\n",
    "g.legend(loc=\"upper right\",bbox_to_anchor=(1.5,1),ncol=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlay Average Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = 1\n",
    "#calculate average of PCA coords\n",
    "ave_embed1 = embed1.groupby(\"cultivar\").mean()\n",
    "ave_embed1[\"cultivar\"] = ave_embed1.index\n",
    "\n",
    "\n",
    "#plot PCA on PC1 and PC2\n",
    "pc = 1\n",
    "g = sns.scatterplot(x=\"PC\"+str(pc), y=\"PC\"+str(pc+1),\n",
    "                data=embed1, hue=\"cultivar\", alpha=1,linewidth=0.1,s=10,hue_order=order)\n",
    "\n",
    "#plot average\n",
    "g = sns.scatterplot(x=\"PC\"+str(pc), y=\"PC\"+str(pc+1),\n",
    "                data=ave_embed1, alpha=1, edgecolor=\"black\", linewidth=1,s=50,hue=\"cultivar\",hue_order=order,legend=None)\n",
    "#add cultivar name near average\n",
    "for line in range(0,ave_embed1.shape[0]):\n",
    "    textpos = [ave_embed1[\"PC\"+str(pc)][line],ave_embed1[\"PC\"+str(pc+1)][line]]\n",
    "    plt.text(textpos[0], textpos[1],ave_embed1[\"cultivar\"][line],size=12)\n",
    "\n",
    "\n",
    "#add variance explained to axis\n",
    "plt.xlabel(\"PC%s (%s %%)\" %\n",
    "           (str(pc), np.round(pca1.explained_variance_ratio_[pc-1]*100, 2)))\n",
    "plt.ylabel(\"PC%s (%s %%)\" % (\n",
    "    str(pc+1), np.round(pca1.explained_variance_ratio_[pc]*100, 2)))\n",
    "    \n",
    "    \n",
    "#add legend\n",
    "g.legend(loc=\"upper right\",bbox_to_anchor=(1.5,1),ncol=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overlay Eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = 1\n",
    "\n",
    "g = sns.scatterplot(x=\"PC\"+str(pc), y=\"PC\"+str(pc+1),\n",
    "                data=embed1, hue=\"cultivar\", alpha=1,linewidth=0.1,s=10,hue_order=order)\n",
    "g.legend(loc=\"upper right\",bbox_to_anchor=(1.5,1),ncol=2, borderaxespad=0.)\n",
    "\n",
    "plt.xlabel(\"PC%s (%s %%)\" %\n",
    "           (str(pc), np.round(pca1.explained_variance_ratio_[pc-1]*100, 2)))\n",
    "plt.ylabel(\"PC%s (%s %%)\" % (\n",
    "    str(pc+1), np.round(pca1.explained_variance_ratio_[pc]*100, 2)))\n",
    "    \n",
    "\n",
    "#eingenvector\n",
    "xs = embed1.iloc[:, pc]\n",
    "ys = embed1.iloc[:, pc+1]\n",
    "coeff = 0.6 * np.transpose(pca1.components_[pc-1:pc-1+2, :])\n",
    "n = coeff.shape[0]\n",
    "scalex = 1.0/(xs.max() - xs.min())\n",
    "scaley = 1.0/(ys.max() - ys.min())\n",
    "\n",
    "for i, var in enumerate(list(_df1)):\n",
    "    plt.arrow(0, 0, coeff[i, 0]/scalex, coeff[i, 1]/scaley, color=\"black\")\n",
    "    plt.text(coeff[i, 0]/scalex, coeff[i, 1]/scaley, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elliptic Fourier Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install via \"pip install pyefd\" if not installed\n",
    "from pyefd import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom function to convert EFD from PC and other..\n",
    "def pc2efv(pca, n, unit):\n",
    "    vec = [0] * len(pca.explained_variance_)\n",
    "    vec[n]= unit * np.sqrt(pca.explained_variance_[n])\n",
    "    vec = np.dot(vec, pca.components_.T) + pca.mean_\n",
    "    vvec = np.array([1,0,0])\n",
    "    return np.concatenate([vvec,vec])\n",
    "def pc2efm(res,n,unit):\n",
    "    efm = pc2efv(res, n, -1*unit)\n",
    "    efm = np.c_[efm,pc2efv(res,n,0)]\n",
    "    efm = np.c_[efm,pc2efv(res,n,unit)]\n",
    "    return efm.T\n",
    "\n",
    "def get_value(pca,xi,yi):\n",
    "    vec = [0] * len(pca.explained_variance_)\n",
    "    vec[0] = xi\n",
    "    vec[1] = yi\n",
    "    vec = np.dot(vec, pca.components_.T) + pca.mean_\n",
    "    vvec = np.array([1,0,0])\n",
    "    return np.concatenate([vvec,vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import efd values\n",
    "\n",
    "import glob\n",
    "features = []\n",
    "names = []\n",
    "for file in glob.glob(\"data/barley/extracted_phenotypes/efd/*\"):\n",
    "    name = os.path.basename(file).split(\".\")[0]\n",
    "    data = np.loadtxt(file,dtype=None,delimiter=\",\")\n",
    "    names.extend([name]*len(data))\n",
    "    features.extend(data)\n",
    "#features = np.array(features)\n",
    "\n",
    "fdf = pd.DataFrame(features).iloc[:,3:]\n",
    "fdf.insert(loc=0,column=\"cultivar\",value = names)\n",
    "fdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca\n",
    "pca2 = PCA(n_components=None)\n",
    "X2 = pca2.fit_transform(fdf.iloc[:,1:])\n",
    "embed2 = pd.DataFrame(X2, columns=[\"PC{}\".format(x + 1) for x in range(len(fdf.columns[1:]))])\n",
    "embed2.insert(loc=0,column=\"cultivar\",value =names)\n",
    "embed2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = 1\n",
    "#calculate average of PCA coords\n",
    "ave_embed2 = embed2.groupby(\"cultivar\").mean()\n",
    "ave_embed2[\"cultivar\"] = ave_embed2.index\n",
    "\n",
    "\n",
    "#plot PCA on PC1 and PC2\n",
    "pc = 1\n",
    "g = sns.scatterplot(x=\"PC\"+str(pc), y=\"PC\"+str(pc+1),\n",
    "                data=embed2, hue=\"cultivar\", alpha=1,linewidth=0.1,s=10,hue_order=order)\n",
    "\n",
    "#plot average\n",
    "g = sns.scatterplot(x=\"PC\"+str(pc), y=\"PC\"+str(pc+1),\n",
    "                data=ave_embed2, alpha=1, edgecolor=\"black\", linewidth=1,s=50,hue=\"cultivar\",hue_order=order,legend=None)\n",
    "#add cultivar name near average\n",
    "for line in range(0,ave_embed2.shape[0]):\n",
    "    textpos = [ave_embed2[\"PC\"+str(pc)][line],ave_embed2[\"PC\"+str(pc+1)][line]]\n",
    "    plt.text(textpos[0], textpos[1],ave_embed2[\"cultivar\"][line],size=8)\n",
    "\n",
    "# the limits are too wide due to outliers. therefore manually setting it.\n",
    "plt.xlim([-0.2,0.2])\n",
    "plt.ylim([-0.04,0.04])\n",
    "    \n",
    "#add variance explained to axis\n",
    "plt.xlabel(\"PC%s (%s %%)\" %\n",
    "           (str(pc), np.round(pca2.explained_variance_ratio_[pc-1]*100, 2)))\n",
    "plt.ylabel(\"PC%s (%s %%)\" % (\n",
    "    str(pc+1), np.round(pca2.explained_variance_ratio_[pc]*100, 2)))\n",
    "    \n",
    "    \n",
    "#add legend\n",
    "g.legend(loc=\"upper right\",bbox_to_anchor=(1.5,1),ncol=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Space Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8\n",
    "grid_y = np.linspace(-0.03, 0.03, n)\n",
    "grid_x = np.linspace(-0.25, 0.25, n)\n",
    "\n",
    "k=1\n",
    "for i, yi in enumerate(grid_y[::-1]):\n",
    "    for j, xi in enumerate(grid_x):\n",
    "        plt.subplot(n,n,k)\n",
    "        plt.axis(\"off\")\n",
    "        value = get_value(pca2,xi,yi)\n",
    "        contours = reconstruct_contour(value.reshape(20,4))\n",
    "        plt.plot(contours[:,0],contours[:,1],color=\"black\",linewidth=2)\n",
    "        plt.fill_between(contours[:,0],contours[:,1],color=\"white\",alpha=0.5)\n",
    "        plt.xlim([-1.2,1.2])\n",
    "        plt.ylim([-1,1])\n",
    "        k +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the shape correlated to each PCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "\n",
    "for i in range(1,5):\n",
    "    plt.subplot(2,2,i)\n",
    "    plt.text(-0.2,-0.01,\"PC\"+str(i))\n",
    "    plt.axis(\"off\")\n",
    "    n = i -1\n",
    "    unit = 2\n",
    "    efms = pc2efm(pca2, n, unit)\n",
    "    for i, style in enumerate([\"dashed\",\"solid\",\"dashed\"]):\n",
    "        contours = reconstruct_contour(efms[i].reshape(20,4))  #pyefd function\n",
    "        plt.plot(contours[:,0],contours[:,1],linestyle=style,color=\"black\")\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input\n",
    "from keras.layers import Conv2D, Flatten, Lambda\n",
    "from keras.layers import Reshape, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\n",
    "import keras.backend as K\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 1\n",
    "image_size = 256\n",
    "kernel_size = 3\n",
    "filters = 32\n",
    "latent_dim = 2\n",
    "input_shape = (image_size, image_size, 3) \n",
    "\n",
    "\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = inputs\n",
    "for i in range(4):\n",
    "    filters *= 2\n",
    "    x = Conv2D(filters=filters,\n",
    "               kernel_size=kernel_size,\n",
    "               activation='relu',\n",
    "               strides=2,\n",
    "               padding='same')(x)\n",
    "\n",
    "shape = K.int_shape(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "\n",
    "\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(shape[1] * shape[2] * shape[3], activation='relu')(latent_inputs)\n",
    "x = Reshape((shape[1], shape[2], shape[3]))(x)\n",
    "for i in range(4):\n",
    "    x = Conv2DTranspose(filters=filters,\n",
    "                        kernel_size=kernel_size,\n",
    "                        activation='relu',\n",
    "                        strides=2,\n",
    "                        padding='same')(x)\n",
    "    filters //= 2\n",
    "\n",
    "outputs = Conv2DTranspose(filters=3,\n",
    "                          kernel_size=kernel_size,\n",
    "                          activation='sigmoid',\n",
    "                          padding='same',\n",
    "                          name='decoder_output')(x)\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae') \n",
    "\n",
    "vae.compile(optimizer='rmsprop',loss=\"mse\")  #a dummy loss. loss does not mean anything in the inference but needed for compiling.\n",
    "\n",
    "#encoder.summary()\n",
    "#decoder.summary()\n",
    "vae.summary()\n",
    "vae.load_weights(\"data/barley/model_weights/VAE.hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze latent vectors extracted from single seed images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(\"data/barley/extracted_phenotypes/VAE_latent.csv\",index_col=0)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get averages as well\n",
    "avedf3 = df3.groupby([\"cultivar\"]).mean()\n",
    "avedf3= avedf3.rename(columns={0:\"Z1\",1:\"Z2\"})\n",
    "avedf3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "g = sns.scatterplot(x=\"Z1\",y=\"Z2\",data=df3,hue = \"cultivar\",linewidth=0.1,alpha=1,s=10,legend=None,hue_order=order)\n",
    "\n",
    "g = sns.scatterplot(x=\"Z1\", y=\"Z2\",\n",
    "                data=avedf3, alpha=1, edgecolor=\"black\", linewidth=1,s=50,hue=avedf3.index,hue_order=order)\n",
    "g.legend(loc=\"upper left\",bbox_to_anchor=(-0.2,-0.2),ncol=8, borderaxespad=0.)\n",
    "\n",
    "for a, row in avedf3.iterrows():\n",
    "    plt.text(row[\"Z1\"],row[\"Z2\"],a,size=8)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Space Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpolation\n",
    "n = 6\n",
    "input_size = 256\n",
    "\n",
    "xn = 8\n",
    "yn = 8\n",
    "grid_y = np.linspace(-8,5,yn) #これが実質y軸方向!\n",
    "grid_x = np.linspace(-3,5,xn)\n",
    "\n",
    "data = np.zeros(((input_size *yn), (input_size * xn), 3))\n",
    "#grid_x = norm.ppf(np.linspace(0.01, 0.99, n))\n",
    "#grid_y = norm.ppf(np.linspace(0.01, 0.99, n))\n",
    "\n",
    "plt.figure(figsize=(8,7))\n",
    "for i, yi in enumerate(grid_y[::-1]):\n",
    "    for j, xi in enumerate(grid_x):\n",
    "        z_sample = np.array([[xi, yi]])\n",
    "        x_decoded = decoder.predict(z_sample)\n",
    "        image = x_decoded[0].reshape(input_size, input_size, 3)\n",
    "        data[i * input_size: (i + 1) * input_size,\n",
    "             j * input_size: (j + 1) * input_size] = image\n",
    "plt.imshow(data)\n",
    "\n",
    "#imsave(\"PCA_latent.jpg\",data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "851.2px",
    "left": "22px",
    "top": "111.6px",
    "width": "409.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
